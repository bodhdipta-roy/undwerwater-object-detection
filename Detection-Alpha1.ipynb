{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f91022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2c9962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnderwaterFishDetector:\n",
    "    def __init__(self, model_path=None):\n",
    "        \"\"\"\n",
    "        Initialize the fish detector\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.load_model(model_path)\n",
    "        \n",
    "        # Detection parameters\n",
    "        self.confidence_threshold = 0.5\n",
    "        self.nms_threshold = 0.4\n",
    "        \n",
    "        # Colors for bounding boxes\n",
    "        self.colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0)]\n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load YOLO model\"\"\"\n",
    "        try:\n",
    "            if model_path and os.path.exists(model_path):\n",
    "                print(f\"Loading custom model from {model_path}\")\n",
    "                self.model = YOLO(model_path)\n",
    "            else:\n",
    "                print(\"Loading YOLOv8 pretrained model...\")\n",
    "                self.model = YOLO('yolov8n.pt')  # nano version for speed\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"Using YOLOv8 nano as fallback\")\n",
    "            self.model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Preprocess frame for underwater conditions\"\"\"\n",
    "        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        \n",
    "        # CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "        l = clahe.apply(l)\n",
    "        \n",
    "        enhanced = cv2.merge([l, a, b])\n",
    "        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
    "        enhanced = self.white_balance_correction(enhanced)\n",
    "        \n",
    "        # Sharpen\n",
    "        kernel = np.array([[-1,-1,-1],\n",
    "                          [-1, 9,-1],\n",
    "                          [-1,-1,-1]])\n",
    "        enhanced = cv2.filter2D(enhanced, -1, kernel * 0.1)\n",
    "        \n",
    "        return enhanced\n",
    "    \n",
    "    def white_balance_correction(self, img):\n",
    "        \"\"\"Simple white balance correction\"\"\"\n",
    "        result = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        avg_a = np.average(result[:, :, 1])\n",
    "        avg_b = np.average(result[:, :, 2])\n",
    "        result[:, :, 1] = result[:, :, 1] - ((avg_a - 128) * (result[:, :, 0] / 255.0) * 1.1)\n",
    "        result[:, :, 2] = result[:, :, 2] - ((avg_b - 128) * (result[:, :, 0] / 255.0) * 1.1)\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_LAB2BGR)\n",
    "        return result\n",
    "    \n",
    "    def detect_fish(self, frame):\n",
    "        \"\"\"Detect fish in the frame\"\"\"\n",
    "        processed_frame = self.preprocess_frame(frame.copy())\n",
    "        results = self.model(processed_frame, conf=self.confidence_threshold, verbose=False)\n",
    "        \n",
    "        detections = []\n",
    "        for result in results:\n",
    "            if result.boxes is not None:\n",
    "                boxes = result.boxes.xyxy.cpu().numpy()\n",
    "                confidences = result.boxes.conf.cpu().numpy()\n",
    "                class_ids = result.boxes.cls.cpu().numpy()\n",
    "                \n",
    "                for i, (box, conf, cls_id) in enumerate(zip(boxes, confidences, class_ids)):\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    class_name = self.model.names[int(cls_id)]\n",
    "                    \n",
    "                    detection = {\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'confidence': conf,\n",
    "                        'class': class_name,\n",
    "                        'class_id': int(cls_id)\n",
    "                    }\n",
    "                    detections.append(detection)\n",
    "                    \n",
    "                    color = self.colors[i % len(self.colors)]\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                    label = f\"{class_name}: {conf:.2f}\"\n",
    "                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "                    cv2.rectangle(frame, (x1, y1 - label_size[1] - 10), \n",
    "                                (x1 + label_size[0], y1), color, -1)\n",
    "                    cv2.putText(frame, label, (x1, y1 - 5), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        return detections, frame\n",
    "    \n",
    "    def run_detection(self):\n",
    "        \"\"\"Run real-time fish detection using webcam\"\"\"\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open webcam\")\n",
    "            return\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 640)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "        \n",
    "        print(\"Starting fish detection... Press 'q' to quit, 's' to save\")\n",
    "        \n",
    "        frame_count, fps_start_time = 0, time.time()\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (640, 640))\n",
    "            detections, processed_frame = self.detect_fish(frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "            if frame_count % 30 == 0:\n",
    "                fps_end_time = time.time()\n",
    "                fps = 30 / (fps_end_time - fps_start_time)\n",
    "                fps_start_time = fps_end_time\n",
    "            else:\n",
    "                fps = 0\n",
    "            \n",
    "            if fps > 0:\n",
    "                cv2.putText(processed_frame, f\"FPS: {fps:.1f}\", (10, 30), \n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(processed_frame, f\"Detections: {len(detections)}\", (10, 60), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.imshow('Underwater Fish Detection', processed_frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('s'):\n",
    "                timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                filename = f\"fish_detection_{timestamp}.jpg\"\n",
    "                cv2.imwrite(filename, processed_frame)\n",
    "                print(f\"Frame saved as {filename}\")\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def train_custom_model(self, dataset_path, epochs=100):\n",
    "        \"\"\"Train a custom YOLO model on fish dataset\"\"\"\n",
    "        print(\"Training custom fish detection model...\")\n",
    "        \n",
    "        config_content = f\"\"\"\n",
    "path: {dataset_path}\n",
    "train: train/images\n",
    "val: valid/images\n",
    "test: test/images\n",
    "nc: 1\n",
    "names: ['fish']\n",
    "\"\"\"\n",
    "        config_path = os.path.join(dataset_path, \"dataset.yaml\")\n",
    "        with open(config_path, 'w') as f:\n",
    "            f.write(config_content)\n",
    "        \n",
    "        model = YOLO('yolov8n.pt')\n",
    "        results = model.train(\n",
    "            data=config_path,\n",
    "            epochs=epochs,\n",
    "            imgsz=640,\n",
    "            batch=16,\n",
    "            name='fish_detection',\n",
    "            save=True,\n",
    "            cache=True,\n",
    "            device=0 if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "        print(\"Training completed!\")\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d94d4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Underwater Fish Detection System\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Dataset Structure Expected:\")\n",
    "    print(\"dataset_root/\")\n",
    "    print(\"├── train/images/, labels/\")\n",
    "    print(\"├── valid/images/, labels/\")\n",
    "    print(\"└── test/images/, labels/\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    detector = UnderwaterFishDetector()\n",
    "    \n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"1. Run real-time detection with webcam\")\n",
    "    print(\"2. Train custom model (requires dataset)\")\n",
    "    \n",
    "    choice = input(\"\\nEnter your choice (1-2): \")\n",
    "    if choice == '1':\n",
    "        detector.run_detection()\n",
    "    elif choice == '2':\n",
    "        dataset_path = input(\"Enter path to dataset directory: \")\n",
    "        if os.path.exists(dataset_path):\n",
    "            epochs = int(input(\"Enter number of epochs (default 100): \") or \"100\")\n",
    "            detector.train_custom_model(dataset_path, epochs)\n",
    "        else:\n",
    "            print(\"Dataset path does not exist!\")\n",
    "    else:\n",
    "        print(\"Invalid choice!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f6461d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underwater Fish Detection System\n",
      "========================================\n",
      "Dataset Structure Expected:\n",
      "dataset_root/\n",
      "├── train/images/, labels/\n",
      "├── valid/images/, labels/\n",
      "└── test/images/, labels/\n",
      "========================================\n",
      "Loading YOLOv8 pretrained model...\n",
      "\n",
      "Options:\n",
      "1. Run real-time detection with webcam\n",
      "2. Train custom model (requires dataset)\n",
      "Training custom fish detection model...\n",
      "Ultralytics 8.3.186 🚀 Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7806MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=fish_detection5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/fish_detection5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/home/bodhdipta/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1/755.1KB 846.9KB/s 0.9s\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4/5.4MB 2.0MB/s 2.7s1s8s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1739.9±1374.4 MB/s, size: 27.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/train/labels... 409 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 409/409 3470.1it/s 0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/train/labels.cache\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.5GB RAM): 100% ━━━━━━━━━━━━ 409/409 5387.9it/s 0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 741.7±440.9 MB/s, size: 29.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/valid/labels... 118 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 118/118 1898.4it/s 0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/valid/labels.cache\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100% ━━━━━━━━━━━━ 118/118 1791.5it/s 0.1s\n",
      "Plotting labels to runs/detect/fish_detection5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/fish_detection5\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30      2.88G      1.699      2.089      1.472        299        640: 100% ━━━━━━━━━━━━ 26/26 6.2it/s 4.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.6it/s 0.7ss\n",
      "                   all        118       2154      0.912      0.412      0.697      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30      3.09G      1.617       1.25      1.429        231        640: 100% ━━━━━━━━━━━━ 26/26 8.8it/s 3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.5it/s 0.4s\n",
      "                   all        118       2154      0.598      0.467       0.52      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30      3.12G      1.588      1.169       1.41        130        640: 100% ━━━━━━━━━━━━ 26/26 8.8it/s 2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.3it/s 0.4s\n",
      "                   all        118       2154      0.195      0.105     0.0946     0.0426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30      3.13G      1.616      1.114      1.408        247        640: 100% ━━━━━━━━━━━━ 26/26 9.0it/s 2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.1it/s 0.4s\n",
      "                   all        118       2154      0.499      0.584      0.512      0.273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30      3.15G      1.568      1.055      1.374        194        640: 100% ━━━━━━━━━━━━ 26/26 8.8it/s 3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.0it/s 0.4s\n",
      "                   all        118       2154      0.646      0.582      0.616      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30      3.17G      1.536      1.026       1.35        253        640: 100% ━━━━━━━━━━━━ 26/26 8.9it/s 2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 8.9it/s 0.5s\n",
      "                   all        118       2154      0.738      0.706      0.774      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30      3.19G      1.556      1.039      1.365        207        640: 100% ━━━━━━━━━━━━ 26/26 9.0it/s 2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.1it/s 0.4s\n",
      "                   all        118       2154      0.858      0.763      0.853      0.461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30       3.2G      1.529     0.9853      1.359        251        640: 100% ━━━━━━━━━━━━ 26/26 9.1it/s 2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.2it/s 0.4s\n",
      "                   all        118       2154      0.871      0.815      0.892      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30      3.22G      1.539      0.994      1.363        202        640: 100% ━━━━━━━━━━━━ 26/26 9.1it/s 2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.5it/s 0.4s\n",
      "                   all        118       2154      0.875      0.798      0.884      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30      3.24G      1.503     0.9562       1.35        215        640: 100% ━━━━━━━━━━━━ 26/26 9.1it/s 2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 8.1it/s 0.5s\n",
      "                   all        118       2154      0.812      0.753       0.84      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30      3.25G      1.519     0.9536      1.352        271        640: 100% ━━━━━━━━━━━━ 26/26 9.1it/s 2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 8.8it/s 0.5s\n",
      "                   all        118       2154      0.873      0.784      0.875      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30      3.27G      1.481     0.9288      1.344        267        640: 100% ━━━━━━━━━━━━ 26/26 9.1it/s 2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.3it/s 0.4s\n",
      "                   all        118       2154      0.876      0.816      0.893        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30      3.29G      1.496     0.9197      1.339        234        640: 100% ━━━━━━━━━━━━ 26/26 9.1it/s 2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.5it/s 0.4s\n",
      "                   all        118       2154      0.856       0.78      0.865      0.465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30       3.3G      1.489     0.9225      1.338        276        640: 100% ━━━━━━━━━━━━ 26/26 9.1it/s 2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.4it/s 0.4s\n",
      "                   all        118       2154      0.885      0.807      0.892      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30      3.32G      1.462     0.8851      1.321        249        640: 100% ━━━━━━━━━━━━ 26/26 9.2it/s 2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.3it/s 0.4s\n",
      "                   all        118       2154      0.876      0.835      0.905      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30      3.34G      1.457     0.8892      1.314        275        640: 100% ━━━━━━━━━━━━ 26/26 9.3it/s 2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.2it/s 0.4s\n",
      "                   all        118       2154       0.87      0.798      0.881      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30      3.36G      1.454     0.8663       1.32        299        640: 100% ━━━━━━━━━━━━ 26/26 9.1it/s 2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.2it/s 0.4s\n",
      "                   all        118       2154      0.853      0.785      0.869       0.47\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/30      3.38G      1.441      0.866      1.312        316        640: 100% ━━━━━━━━━━━━ 26/26 9.2it/s 2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.5it/s 0.4s\n",
      "                   all        118       2154      0.881      0.842      0.909      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/30      3.39G      1.441     0.8474      1.306        237        640: 100% ━━━━━━━━━━━━ 26/26 9.2it/s 2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.4it/s 0.4s\n",
      "                   all        118       2154      0.873      0.805      0.878      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/30      3.41G      1.422     0.8433       1.31        241        640: 100% ━━━━━━━━━━━━ 26/26 9.3it/s 2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.2it/s 0.4s\n",
      "                   all        118       2154      0.897      0.831      0.909      0.526\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/30      3.43G      1.469     0.8661       1.34        158        640: 100% ━━━━━━━━━━━━ 26/26 9.1it/s 2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.0it/s 0.4s\n",
      "                   all        118       2154      0.887       0.83      0.904      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/30      3.44G      1.451     0.8373       1.33        178        640: 100% ━━━━━━━━━━━━ 26/26 9.9it/s 2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 8.9it/s 0.4s\n",
      "                   all        118       2154      0.889      0.831      0.905       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/30      3.46G      1.437     0.8259       1.31        158        640: 100% ━━━━━━━━━━━━ 26/26 10.1it/s 2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.3it/s 0.4s\n",
      "                   all        118       2154       0.89      0.819      0.901      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/30      3.47G      1.426     0.8103      1.302        160        640: 100% ━━━━━━━━━━━━ 26/26 9.9it/s 2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.1it/s 0.4s\n",
      "                   all        118       2154      0.885      0.839      0.904      0.517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/30      3.49G      1.421     0.7944      1.309        133        640: 100% ━━━━━━━━━━━━ 26/26 10.0it/s 2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.7it/s 0.4s\n",
      "                   all        118       2154      0.888      0.843      0.904      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/30      3.51G      1.405     0.7777      1.305        143        640: 100% ━━━━━━━━━━━━ 26/26 9.9it/s 2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.7it/s 0.4s\n",
      "                   all        118       2154      0.894      0.842      0.907      0.533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/30      3.53G      1.401     0.7725      1.302        161        640: 100% ━━━━━━━━━━━━ 26/26 10.1it/s 2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.6it/s 0.4s\n",
      "                   all        118       2154      0.904      0.844      0.918      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/30      3.54G      1.385     0.7662      1.286        146        640: 100% ━━━━━━━━━━━━ 26/26 9.9it/s 2.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.5it/s 0.4s\n",
      "                   all        118       2154        0.9      0.849      0.919      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/30      3.56G      1.377     0.7574      1.291        168        640: 100% ━━━━━━━━━━━━ 26/26 10.0it/s 2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.8it/s 0.4s\n",
      "                   all        118       2154      0.903      0.847      0.923      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/30      3.58G      1.379     0.7569      1.293        147        640: 100% ━━━━━━━━━━━━ 26/26 9.9it/s 2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 9.4it/s 0.4s\n",
      "                   all        118       2154      0.908      0.852      0.924      0.544\n",
      "\n",
      "30 epochs completed in 0.028 hours.\n",
      "Optimizer stripped from runs/detect/fish_detection5/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/fish_detection5/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/fish_detection5/weights/best.pt...\n",
      "Ultralytics 8.3.186 🚀 Python-3.12.11 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7806MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 4.3it/s 0.9s\n",
      "                   all        118       2154      0.908      0.851      0.924      0.544\n",
      "Speed: 0.2ms preprocess, 1.5ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/fish_detection5\u001b[0m\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d61023ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1008_jpg.rf.f0b0942e2c7d4e83fb55492060d6da1b.jpg: 640x640 19 fishs, 2.9ms\n",
      "image 2/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1126_jpg.rf.6ce0aef287cdb7f6b8b65fd2178ef637.jpg: 640x640 10 fishs, 2.9ms\n",
      "image 3/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1133_jpg.rf.b4be115c688f2e3b65883180aa034f35.jpg: 640x640 21 fishs, 2.9ms\n",
      "image 4/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1188_jpg.rf.6c85ef65438c5884661129e1da5da478.jpg: 640x640 16 fishs, 2.8ms\n",
      "image 5/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1239_jpg.rf.2ff6118ab6051e6a8f9c74a65d2963d5.jpg: 640x640 17 fishs, 2.8ms\n",
      "image 6/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1241_jpg.rf.920957b398a5a92d86d20626ae11be99.jpg: 640x640 16 fishs, 2.9ms\n",
      "image 7/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1314_jpg.rf.f22168b9d1a5c6e2640683e0a03d321b.jpg: 640x640 15 fishs, 2.8ms\n",
      "image 8/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame140_jpg.rf.545305965df5deb591e61da9a1b8cef6.jpg: 640x640 25 fishs, 2.9ms\n",
      "image 9/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1485_jpg.rf.6419f1bba399517e3e5705084c9deed4.jpg: 640x640 13 fishs, 2.8ms\n",
      "image 10/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame151_jpg.rf.186cabda857bccd3162cd01972352b93.jpg: 640x640 25 fishs, 2.8ms\n",
      "image 11/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1618_jpg.rf.9f08ae1f9294bd351c07aa4d1f223252.jpg: 640x640 7 fishs, 2.8ms\n",
      "image 12/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame162_jpg.rf.228d359ea40530903d519b8577acd17b.jpg: 640x640 (no detections), 2.8ms\n",
      "image 13/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1664_jpg.rf.353d65fdc0be73888951e1c08f572d34.jpg: 640x640 12 fishs, 2.8ms\n",
      "image 14/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1691_jpg.rf.42159f831a80ae0defd98f5bf4017e33.jpg: 640x640 12 fishs, 2.9ms\n",
      "image 15/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1753_jpg.rf.d1e06fed57aa8640c578dbbc11f71a37.jpg: 640x640 10 fishs, 2.8ms\n",
      "image 16/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame1944_jpg.rf.56a24b6a9d847c44df41fba5e362801a.jpg: 640x640 14 fishs, 2.9ms\n",
      "image 17/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame196_jpg.rf.ea771b7eea79fdbdb8f377fa20f55fa8.jpg: 640x640 13 fishs, 2.8ms\n",
      "image 18/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2051_jpg.rf.ed9f660f8f62357872ced769ba9cbfd6.jpg: 640x640 10 fishs, 2.8ms\n",
      "image 19/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2063_jpg.rf.79a3dd2e5b54eff2c99dfb558cb244a2.jpg: 640x640 11 fishs, 2.8ms\n",
      "image 20/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2091_jpg.rf.4a307a65043bb0184163052613469fa8.jpg: 640x640 20 fishs, 2.8ms\n",
      "image 21/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2096_jpg.rf.16e86929d085264671ada7a5dc68d652.jpg: 640x640 20 fishs, 2.8ms\n",
      "image 22/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame216_jpg.rf.507be0c20339bbacb86ed50b814481d0.jpg: 640x640 16 fishs, 2.8ms\n",
      "image 23/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2287_jpg.rf.1cc355c70390c267fc6623380b5feb0d.jpg: 640x640 16 fishs, 2.8ms\n",
      "image 24/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2289_jpg.rf.3435a1f5904ca3f74f67450847c87fcd.jpg: 640x640 15 fishs, 2.8ms\n",
      "image 25/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2353_jpg.rf.dd6f1406926a39c9558f420a49fbf9db.jpg: 640x640 17 fishs, 2.8ms\n",
      "image 26/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2395_jpg.rf.e3af28dfc851b41f89b526eb060349ef.jpg: 640x640 16 fishs, 2.8ms\n",
      "image 27/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame23_jpg.rf.88e2d7e08b61d8e86b4e00b9a7e63975.jpg: 640x640 24 fishs, 2.9ms\n",
      "image 28/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2418_jpg.rf.328087c253e57d3a1b857d48fc823fb7.jpg: 640x640 15 fishs, 2.8ms\n",
      "image 29/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame247_jpg.rf.fb886a120524a23db6c52dcde06de87f.jpg: 640x640 15 fishs, 2.9ms\n",
      "image 30/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame250_jpg.rf.619589fd9de9d769f133c04cf69d7167.jpg: 640x640 16 fishs, 3.1ms\n",
      "image 31/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame252_jpg.rf.21e04ba1e292d360f838f038613b3e0c.jpg: 640x640 3 fishs, 2.8ms\n",
      "image 32/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame259_jpg.rf.1206f9ed04c2d8a25c26c25eccc05381.jpg: 640x640 15 fishs, 2.8ms\n",
      "image 33/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame25_jpg.rf.240dbaf371550727d4c25822ebeb369b.jpg: 640x640 14 fishs, 2.8ms\n",
      "image 34/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2624_jpg.rf.bcfaf27ae8108ad42743760ade8d964f.jpg: 640x640 10 fishs, 2.8ms\n",
      "image 35/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2631_jpg.rf.d687d3879e25c2ee2bdde6327faa92e1.jpg: 640x640 14 fishs, 2.8ms\n",
      "image 36/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2635_jpg.rf.7e9d9b8c7ef2e1ea4683cb18653eb645.jpg: 640x640 15 fishs, 3.0ms\n",
      "image 37/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2671_jpg.rf.f25755e9c3c2fe59fbc3fe4b60a4d3b6.jpg: 640x640 4 fishs, 2.8ms\n",
      "image 38/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2681_jpg.rf.fed00be7e053c8421cbdac637088724c.jpg: 640x640 7 fishs, 2.8ms\n",
      "image 39/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame268_jpg.rf.ec2423a3576ba4388865ac0504c4fc8b.jpg: 640x640 16 fishs, 2.8ms\n",
      "image 40/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2854_jpg.rf.c00cb3ea620a9fa36ee061e22dd717c3.jpg: 640x640 12 fishs, 2.8ms\n",
      "image 41/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame2878_jpg.rf.46027218085de93bccddeabe7ff35100.jpg: 640x640 11 fishs, 2.8ms\n",
      "image 42/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame326_jpg.rf.9cd893b5a5cc6845e7c6acbbdca38d2d.jpg: 640x640 2 fishs, 3.4ms\n",
      "image 43/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame359_jpg.rf.5598562a1c5a6eba1985380c81f746c8.jpg: 640x640 22 fishs, 3.5ms\n",
      "image 44/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame362_jpg.rf.afa0915d6bfad2b712bead4d8000a6fe.jpg: 640x640 21 fishs, 2.8ms\n",
      "image 45/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame432_jpg.rf.05a547f5608fdf7e7fb1c16d48b887a5.jpg: 640x640 19 fishs, 2.8ms\n",
      "image 46/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame51_jpg.rf.9fc38ca9cfb9d44b05999bf4c7bc8d1f.jpg: 640x640 22 fishs, 2.8ms\n",
      "image 47/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame614_jpg.rf.934edbdefa3c3e08942c3fbcfb60cb33.jpg: 640x640 21 fishs, 2.8ms\n",
      "image 48/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame68_jpg.rf.ae5e6008a40c488f22d57222500b0b03.jpg: 640x640 22 fishs, 2.8ms\n",
      "image 49/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame734_jpg.rf.ddd1716b8071cabe46686ba19a1f2b27.jpg: 640x640 7 fishs, 2.8ms\n",
      "image 50/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame737_jpg.rf.5af8d8a9d82618c6472df2efcceb4099.jpg: 640x640 10 fishs, 2.8ms\n",
      "image 51/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame740_jpg.rf.750b0bf9b20cfdab509cb9e58d1d703d.jpg: 640x640 18 fishs, 2.8ms\n",
      "image 52/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame779_jpg.rf.600dcab43c36fb25a43c771a42b2e651.jpg: 640x640 27 fishs, 2.8ms\n",
      "image 53/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame781_jpg.rf.a06863bf83658546f252dad2c5def97c.jpg: 640x640 5 fishs, 2.8ms\n",
      "image 54/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame807_jpg.rf.174b38d39a88d7adce368fd25f9f0e04.jpg: 640x640 (no detections), 2.8ms\n",
      "image 55/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame828_jpg.rf.059da6d31dacff94589aec40fff4d211.jpg: 640x640 26 fishs, 2.8ms\n",
      "image 56/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame842_jpg.rf.849801acceadf61b8394ed0d0f8ba90c.jpg: 640x640 22 fishs, 3.0ms\n",
      "image 57/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame851_jpg.rf.f74601c51ed0c2dcfeacaa25ca7709eb.jpg: 640x640 22 fishs, 2.8ms\n",
      "image 58/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame861_jpg.rf.0e36b954d695d1954c06e091e41d0481.jpg: 640x640 17 fishs, 2.9ms\n",
      "image 59/59 /home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images/frame944_jpg.rf.8509eae1cd0023ea6e77c09265f14975.jpg: 640x640 17 fishs, 2.8ms\n",
      "Speed: 0.8ms preprocess, 2.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load trained model\n",
    "model = YOLO(\"runs/detect/fish_detection5/weights/best.pt\")\n",
    "\n",
    "# Run on a folder of images\n",
    "results = model.predict(source=\"/home/bodhdipta/Downloads/Minor Project/Etroplus_maculatus/test/images\", conf=0.5, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3978e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Underwater Fish Detection System\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Dataset Structure Expected:\")\n",
    "    print(\"dataset_root/\")\n",
    "    print(\"├── train/images/, labels/\")\n",
    "    print(\"├── valid/images/, labels/\")\n",
    "    print(\"└── test/images/, labels/\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    detector = UnderwaterFishDetector(model_path=\"runs/detect/fish_detection5/weights/best.pt\")\n",
    "    \n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"1. Run real-time detection with webcam\")\n",
    "    print(\"2. Train custom model (requires dataset)\")\n",
    "    \n",
    "    choice = input(\"\\nEnter your choice (1-2): \")\n",
    "    if choice == '1':\n",
    "        detector.run_detection()\n",
    "    elif choice == '2':\n",
    "        dataset_path = input(\"Enter path to dataset directory: \")\n",
    "        if os.path.exists(dataset_path):\n",
    "            epochs = int(input(\"Enter number of epochs (default 100): \") or \"100\")\n",
    "            detector.train_custom_model(dataset_path, epochs)\n",
    "        else:\n",
    "            print(\"Dataset path does not exist!\")\n",
    "    else:\n",
    "        print(\"Invalid choice!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
